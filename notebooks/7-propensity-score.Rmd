---
title: "Propensity score weighting: regresja logistyczna i propensity score"
output: html_notebook
---


# Pakiety

```{r}
library(CBPS) ## covariate bapancing propensity score
library(tidyverse)
```

+ CBPS -- główna funkcja do szacowania prawdopodobieństwa przynależności do źródła nielosowego
+ hdCBPS -- do większych danych, zarówno pod względem liczby wierszy, jak i liczby zmiennych
+ npCBPS -- non-parametric CBPS -- wyłącznie dane jakościowe (wszystkie X są zmiennymi jakościowymi)

# Wczytujemy dane

```{r}
df <- readRDS("../data-raw/data_for_lecture.rds")
head(df)
```

# Regresja logistyczna

1. przeanalizować dane np. wizualizacje, test $\chi^2$, inne testy
2. można zabrać się za budowanie modelu

stats::glm
proc glm / proc logistic / proc genmod
statsmodels.glm

Zakładamy, że budujemy następujący model

$$
P(\text{status}=1| \text{gender}) = \frac{\exp(\beta_0 + \beta_1 \text{gender})}{1 + \exp(\beta_0 + \beta_1 \text{gender})}
$$
```{r}
m1 <- glm(formula = status ~ gender, data = df, family = binomial(link = "logit")) ## binomial(), "binomial"
summary(m1)
```

Ilorazy szans

```{r}
exp(coef(m1))
```

Ilorazy szans z przedziałem ufności 

```{r}
exp(confint(m1))
```

Chcemy otrzymać wektor $\hat{\rho}$ należy użyć funkcji fitted (predict)

```{r}
rho <- fitted(m1)
summary(1/rho)
```

Budujemy większy model

```{r}
m2 <- update(m1, . ~ . + age + factor(woj) + factor(locality))
summary(m2)
```

```{r}
hist(fitted(m2), breaks = "scott", main = expression(hat(rho)))
hist(1/fitted(m2), breaks = "scott", main = expression(1/hat(rho)))
```




```{r}
set.seed(123)
N_pop <- 1e4
## generuję dane dla populacji
X_1 <- rbinom(n = N_pop, size = 1, prob = 0.45) ## płeć
X_2 <- rpois(n = N_pop, lambda = 2) ## liczba dzieci
X_3 <- rbinom(n = N_pop, size = 1, prob = 0.7) ## miejsce zamieszkania (1=wies, 0=miasto)
epsilon <- rnorm(n = N_pop, mean = 0, sd = 10)
Y <- 200 + 20*X_1 - 30*X_3 + epsilon
pop_data <- data.frame(Y = Y, X_1 = factor(X_1), X_2, X_3 = factor(X_3))

## generuję zmienna określającą przynależnosć do big data
rho <-  exp(10 + X_2 - 15*X_3) / (1 + exp(10 + X_2 - 15*X_3))
R <- rbinom(n = N_pop, size = 1,  prob = rho)

big_data_inc <- which(R == 1)
big_data <- pop_data[big_data_inc,]
big_data$waga <- nrow(pop_data)/nrow(big_data) ## WAGA = N / n

## próbę losową o wartości 3000
proba_losowa <- pop_data[sample(1:nrow(pop_data), size = 3000),]
c(Prawda = mean(pop_data$Y), Losowa = mean(proba_losowa$Y), Big_data = mean(big_data$Y))
```


1. należy połączyć obydwa zbiory danych (dane1, dane2)

```{r}
dane_model <- big_data %>% mutate(R = 1) %>%
  bind_rows(proba_losowa %>% mutate(R = 0))

summary(dane_model)
```


2. szacujemy model z wykorzystaniem funkcji CBPS albo hdCBPS

```{r}
model1 <- CBPS(formula = R ~ X_1 + X_2 + X_3, data = dane_model, ATT = 1)
```

3. Patrzymy na wyniki

```{r}
model1
```


```{r}
summary(model1)
```

4. Wyciągamy wagi dla poszczególnych rekordów

```{r}
str(model1,1)

dane_model <- dane_model %>%
  mutate(wagi = 1/model1$fitted.values)
```

5. szacujemy Y dla źródła big data

```{r}
dane_model %>%
  filter(R == 1) %>%
  summarise(mean = weighted.mean(Y, wagi))
```

```{r}
c(Prawda = mean(pop_data$Y), Losowa = mean(proba_losowa$Y), Big_data = mean(big_data$Y))
```

```{r}
model2 <- hdCBPS(formula = R ~ X_1 + X_2 + X_3,  data = dane_model, y = dane_model$Y, ATT = 0)

dane_model <- dane_model %>% mutate(wagi2 = 1/model2$fitted.values)

dane_model %>%
  summarise(prop1 = sum(Y*R*wagi)/sum(R*wagi),
            prop2 = sum(Y*R*wagi2)/sum(R*wagi2))

```

Teraz drugie podejście -- łączymy źródło big data z danymi populacji

```{r}
dane_model2 <- big_data %>% mutate(R = 1) %>%
  bind_rows(pop_data %>% mutate(R = 0))
```

```{r}
model_pop1 <- CBPS(formula = R ~ X_1 + X_2 + X_3, data = dane_model2, ATT = 1)
```

```{r}
model_pop2 <- hdCBPS(formula = R ~ X_1 + X_2 + X_3,  data = dane_model2, y = dane_model2$Y, ATT = 0)
```


```{r}
dane_model2 %>%
  mutate(wagi1 = 1/model_pop1$fitted.values,
         wagi2 = 1/model_pop2$fitted.values) %>%
  summarise(prop1 = sum(Y*R*wagi1)/sum(R*wagi1),
            prop2 = sum(Y*R*wagi2)/sum(R*wagi2),
            naive = sum(Y*R)/sum(R),
            true = sum(Y*(R==0))/sum((R==0)))
```

A teraz kolejna opcja -- wyrzucamy z ze zbioru populacji te jednostki, które są w zbiorze big data

```{r}
dane_model3 <- big_data %>% mutate(R = 1) %>%
  bind_rows(pop_data[-big_data_inc,] %>% mutate(R = 0))
```

```{r}
model3_pop1 <- CBPS(formula = R ~ X_1 + X_2 + X_3, data = dane_model3, ATT = 1)
model3_pop2 <- hdCBPS(formula = R ~ X_1 + X_2 + X_3, data = dane_model3, y = dane_model3$Y, ATT = 0)
```

```{r}
dane_model3 %>%
  mutate(wagi1 = 1/model3_pop1$fitted.values,
         wagi2 = 1/model3_pop2$fitted.values) %>%
  summarise(prop1 = sum(Y*R*wagi1)/sum(R*wagi1),
            prop2 = sum(Y*R*wagi2)/sum(R*wagi2),
            naive = sum(Y*R)/sum(R),
            true =  mean(Y))
```

Wniosek: istotna jest identyfikacja jednostek, które są w źródle big data i poza big data.

